{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effective-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from tqdm import tqdm\n",
    "import catboost as ctb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intensive-while",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3409, 97), (3410, 96), (6819, 97))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_hdf(\"../input/train_taiwan.h5\")\n",
    "df_test = pd.read_hdf(\"../input/test_taiwan.h5\")\n",
    "\n",
    "df_all = pd.concat([df_train, df_test]).reset_index(drop=True)\n",
    "df_all.columns = [x.replace(\" \", \"_\").lower() for x in df_all.columns]\n",
    "\n",
    "df_train.shape, df_test.shape, df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "biblical-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment(model, feats=None, threshold=0.5, n_splits=3, black_list=[\"target\"], show_feats=False, show_cr=False, show_cm=False, show_pr=False, show_lc=False):\n",
    "    if feats is None:\n",
    "        num_feats = df_all.select_dtypes(\"number\").columns\n",
    "        feats = [x for x in num_feats if x not in black_list]\n",
    "\n",
    "    if show_feats:\n",
    "        print(feats)\n",
    "        \n",
    "    df_train = df_all[ df_all[\"target\"].notnull() ]\n",
    "    X_train = df_train[feats].values\n",
    "    y_train = df_train[\"target\"].values\n",
    "\n",
    "    scores = []\n",
    "    cv=StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    for train_idx, test_idx in cv.split(X_train, y_train):    \n",
    "\n",
    "        model.fit(X_train[train_idx], y_train[train_idx])\n",
    "\n",
    "        y_probas = model.predict_proba(X_train[test_idx])\n",
    "        y_pred = (y_probas[:,1] > threshold).astype(np.int)\n",
    "        #y_pred = model.predict(X_train[test_idx])\n",
    "\n",
    "        if show_cr:\n",
    "            print(classification_report(y_train[test_idx], y_pred))\n",
    "        \n",
    "        if show_cm:\n",
    "            skplt.metrics.plot_confusion_matrix(y_train[test_idx], y_pred)#normalize=True\n",
    "            \n",
    "        if show_pr:\n",
    "            skplt.metrics.plot_precision_recall(y_train[test_idx], y_probas)\n",
    "\n",
    "        score = f1_score(y_train[test_idx], y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"Score: \", np.mean(scores), np.std(scores))\n",
    "    \n",
    "    skplt.estimators.plot_learning_curve(model, X_train, y_train, cv=cv, scoring=\"f1\", random_state=0)\n",
    "    \n",
    "    return eli5.show_weights(model, feature_names=feats, top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth=5, n_estimators=100, random_state=0)\n",
    "make_experiment(model, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ctb.CatBoostClassifier(max_depth=5, n_estimators=100, verbose=0)\n",
    "make_experiment(model, threshold=0.1, show_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(max_depth=5, n_estimators=100)\n",
    "make_experiment(model, threshold=0.1, show_cm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-white",
   "metadata": {},
   "source": [
    "najlepsze cechy z eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "irish-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feats =[\n",
    "    \"borrowing_dependency\",\n",
    "    \"interest-bearing_debt_interest_rate\",\n",
    "    \"net_income_to_total_assets\",\n",
    "    \"average_collection_days\",\n",
    "    \"non-industry_revenue_and_expenditure/revenue\",\n",
    "    \"continuous_profit_rate_(after_tax)\",\n",
    "    \"net_worth_growth_rate\",\n",
    "    \"permanent_net_profit_growth_rate\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-emphasis",
   "metadata": {},
   "source": [
    "tworzenie nowych cech z best_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-establishment",
   "metadata": {},
   "source": [
    "logarytm i pierwiastek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fundamental-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in best_feats:\n",
    "    df_all['log_' + feat] = df_all[feat].map(lambda x: np.log1p(x))\n",
    "    df_all['sqrt_' + feat] = df_all[feat].map(lambda x: np.sqrt(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-organ",
   "metadata": {},
   "source": [
    "dzielenie wartości na 5 przedziałów i factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "monetary-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in best_feats:\n",
    "    df_all[feat + \"_range\"]=pd.cut(df_all[feat],5).factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-mailman",
   "metadata": {},
   "source": [
    "transformacja wielomianowa 2 stopnia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exempt-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_all[best_feats].copy()\n",
    "trans = PolynomialFeatures(degree=2)\n",
    "df_temp = pd.DataFrame(trans.fit_transform(df_temp))\n",
    "df_all = pd.concat([df_all, df_temp], axis = 1)\n",
    "df_all.columns=df_all.columns.map(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-renaissance",
   "metadata": {},
   "source": [
    "wygenerowanie par i dodawanie/odejmowanie parami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "secondary-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for i,x in enumerate(best_feats):\n",
    "    if i == 0: continue\n",
    "    pairs.append((best_feats[0], x))\n",
    "\n",
    "for i,x in enumerate(best_feats):\n",
    "    if i == 1: continue\n",
    "    pairs.append((best_feats[1], x))\n",
    "\n",
    "for i,x in enumerate(best_feats):\n",
    "    if i == 2: continue\n",
    "    pairs.append((best_feats[2], x))\n",
    "\n",
    "for i,x in enumerate(best_feats):\n",
    "    if i == 3: continue\n",
    "    pairs.append((best_feats[3], x))\n",
    "    \n",
    "for i,x in enumerate(best_feats):\n",
    "    if i == 4: continue\n",
    "    pairs.append((best_feats[4], x))\n",
    "\n",
    "for i,x in enumerate(best_feats):\n",
    "    if i == 5: continue\n",
    "    pairs.append((best_feats[5], x))\n",
    "\n",
    "for i,x in enumerate(best_feats):\n",
    "    if i == 6: continue\n",
    "    pairs.append((best_feats[6], x))\n",
    "\n",
    "for i,x in enumerate(best_feats):\n",
    "    if i == 7: continue\n",
    "    pairs.append((best_feats[7], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sensitive-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_pairs = pairs\n",
    "\n",
    "for left, right in sum_pairs:\n",
    "    output_feat = 'add_{0}_{1}'.format(left, right)\n",
    "    df_all[output_feat] = df_all[left] + df_all[right]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "offensive-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_pairs = pairs\n",
    "\n",
    "for left, right in minus_pairs:\n",
    "    output_feat = 'min_{0}_{1}'.format(left, right)\n",
    "    df_all[output_feat] = df_all[left] - df_all[right]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-village",
   "metadata": {},
   "source": [
    "faktoryzacja wartości na podstawie średniej/mediany w kolumnie na zasadzie x < m->0, x > m->1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intelligent-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in best_feats:\n",
    "    median_ = df_all[feat].median() \n",
    "    mean_ = df_all[feat].mean()\n",
    "    df_all[feat + \"_med_cut\"]=df_all[feat].map(lambda x: 1 if x > median_ else 0)\n",
    "    df_all[feat + \"_mean_cut\"]=df_all[feat].map(lambda x: 1 if x > mean_ else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-envelope",
   "metadata": {},
   "source": [
    "obcięcie wierzy z wartościami odstającymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intelligent-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat_name in best_feats:    \n",
    "    min_value = df_all[feat_name].quantile(0.01)\n",
    "    max_value = df_all[feat_name].quantile(0.99)\n",
    "    df_all = df_all[(df_all[feat_name] > min_value) & (df_all[feat_name] < max_value) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ctb.CatBoostClassifier(max_depth=7, n_estimators=100, verbose=0)\n",
    "make_experiment(model, threshold=0.1, show_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-basics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
